{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "- Start with problem/objective of project\n",
    "- Go into how your project will solve that\n",
    "\n",
    "Natural disasters are unpreventable, we can try and predict when the disasters will happen, but can't stop them. In this report, instead of prediciting a natural disater, we will predict the aftermath of the destruction. Given a dataset that contains information about a building's architect and history, we use keras' deep learning neural network on these feature to fit our model. The objective is to predict the damage that occured on these buildings after the Nepal Earthquake in 2015. The buildings have a damge grade score from 1,having low damage, to 3, complete destruction. The most significant features were ______ when predicting the damage grade. TESTING> RESULTS> CONCLUSION.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature reviews/Related Work\n",
    "- How others have tried to solve this problem and your unique novelty/contribution on solving the problem.\n",
    "- Include proper citation of book, journal, websites "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detail of your approach/Proposed Method\n",
    "- Discuss the detail of your model/architecture -- keras\n",
    "- exploratory data analysis (descriptive and visual) \n",
    "- novelty.\n",
    "- preprocessing data\n",
    "    - standardized the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset comes from the Driven Data competition, Richter's Predictor: Modeling Earthquake Damage (https://www.drivendata.org/competitions/57/nepal-earthquake/page/134/). The data was collected through surveys by the Central Bureau of Statistics after the 2015 earthquake in Nepal and is one of the largest post-disaster datasets ever collected. The data consists of three datasets: train values, train labels, and test values. The train and test values comprise of 260,601 and 86,868 rows respectively with 39 variables. These variables are mainly comprised of the buildings’ structure. Both values and labels datasets contain the buildings’ id, and the train labels dataset also includes the damage grade for that building. The damage grade is represented by 3 levels; 1 represents low damage, 2 represents a medium amount of damage, and 3 represents almost complete destruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***insert train labels dataframe***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Datasets\n",
    "The datasets collected through the Driven Data competition was relatively clean. After the compilation of respective datasets into a data frame by the get_data function, exploratory analysis confirmed that there were no missing values and each variable contained the correct corresponding datatypes. The variables in the train values dataset contained both numeric and categorical data. Dummy variables were created from the categorical data, this increased the number of variables to 61. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "The first step when exploring the data, was to look at the distribution of the damage grades. Damage grade at level 2 makes up more than 50% of the outcomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment detail\n",
    "- Exploratory data analysis\n",
    "- plot of loss, accuracy, visualization and their explanation\n",
    "- final f1 score\n",
    "\n",
    "The train labels comprised of damage grade were interpreted as categorical, and a one-hot encoding was applied to transform the labels into three classes. \n",
    "The objective of this competition is to predict the damage grade of the buildings in the test values dataset. Therefore, since the test labels dataset was not given, in order to build the predictive model, the training values and labels were split into train and validate datasets. The training data was split 80%/20% to randomly select the training and validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis\n",
    "- Can you explain where your model/visualization is not working properly and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
